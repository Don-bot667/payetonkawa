# ğŸ« TICKETS MSPR PayeTonKawa

**DerniÃ¨re mise Ã  jour :** 2026-02-25  
**Statut actuel :** 67 tests âœ… | 87% couverture | RabbitMQ âŒ | CI/CD âŒ  
**Temps total estimÃ© :** ~12h

---

## ğŸ“‹ SOMMAIRE

| Phase | Tickets | PrioritÃ© | Temps |
|-------|---------|----------|-------|
| 1. RabbitMQ | #001-#006 | ğŸ”´ Critique | ~3h30 |
| 2. CI/CD | #007-#009 | ğŸ”´ Critique | ~1h30 |
| 3. Monitoring | #010-#012 | ğŸŸ¡ Important | ~1h |
| 4. Tests | #013-#014 | ğŸŸ¡ Important | ~1h |
| 5. Documentation | #015-#019 | ğŸ”´ Critique | ~3h |
| 6. Postman | #020 | ğŸ”´ Critique | ~45min |
| 7. Conduite du changement | #021 | ğŸ”´ Critique | ~1h30 |

---

# PHASE 1 â€” RABBITMQ (Message Broker)
> **Obligatoire** : synchronisation entre micro-services

---

## ğŸ« TICKET #001 â€” CrÃ©er module RabbitMQ pour api-clients

**PrioritÃ© :** ğŸ”´ Critique  
**Estimation :** 30 min  
**Fichiers Ã  crÃ©er :** `api-clients/app/rabbitmq.py`

### Description
ImplÃ©menter la connexion RabbitMQ et la publication de messages quand un client est crÃ©Ã©, modifiÃ© ou supprimÃ©.

### Code Ã  implÃ©menter

```python
# api-clients/app/rabbitmq.py
import pika
import json
import os
import logging

logger = logging.getLogger(__name__)

RABBITMQ_URL = os.getenv("RABBITMQ_URL", "amqp://guest:guest@localhost:5672/")
EXCHANGE_NAME = "payetonkawa"

def get_connection():
    """Ã‰tablit une connexion Ã  RabbitMQ"""
    try:
        parameters = pika.URLParameters(RABBITMQ_URL)
        return pika.BlockingConnection(parameters)
    except Exception as e:
        logger.error(f"Erreur connexion RabbitMQ: {e}")
        return None

def publish_message(routing_key: str, message: dict):
    """Publie un message sur RabbitMQ"""
    try:
        connection = get_connection()
        if not connection:
            return False
            
        channel = connection.channel()
        
        # DÃ©clare l'exchange (type: topic pour flexibilitÃ©)
        channel.exchange_declare(
            exchange=EXCHANGE_NAME, 
            exchange_type='topic', 
            durable=True
        )
        
        # Publie le message
        channel.basic_publish(
            exchange=EXCHANGE_NAME,
            routing_key=routing_key,
            body=json.dumps(message),
            properties=pika.BasicProperties(
                delivery_mode=2,  # Message persistant
                content_type='application/json'
            )
        )
        connection.close()
        logger.info(f"Message publiÃ©: {routing_key}")
        return True
    except Exception as e:
        logger.error(f"Erreur publication RabbitMQ: {e}")
        return False

# === Fonctions spÃ©cifiques clients ===

def publish_client_created(client_id: int, client_data: dict):
    """Publie un Ã©vÃ©nement de crÃ©ation de client"""
    publish_message("client.created", {
        "event": "client_created",
        "client_id": client_id,
        "data": client_data,
        "timestamp": __import__('datetime').datetime.utcnow().isoformat()
    })

def publish_client_updated(client_id: int, client_data: dict):
    """Publie un Ã©vÃ©nement de modification de client"""
    publish_message("client.updated", {
        "event": "client_updated",
        "client_id": client_id,
        "data": client_data,
        "timestamp": __import__('datetime').datetime.utcnow().isoformat()
    })

def publish_client_deleted(client_id: int):
    """Publie un Ã©vÃ©nement de suppression de client"""
    publish_message("client.deleted", {
        "event": "client_deleted",
        "client_id": client_id,
        "timestamp": __import__('datetime').datetime.utcnow().isoformat()
    })
```

### DÃ©pendance Ã  ajouter
```bash
# api-clients/requirements.txt
pika==1.3.2
```

### CritÃ¨res d'acceptation
- [ ] Connexion Ã  RabbitMQ fonctionnelle
- [ ] Exchange "payetonkawa" crÃ©Ã© (type: topic, durable)
- [ ] 3 fonctions : `publish_client_created`, `publish_client_updated`, `publish_client_deleted`
- [ ] Gestion des erreurs (l'API ne crash pas si RabbitMQ down)
- [ ] Logs des publications

---

## ğŸ« TICKET #002 â€” IntÃ©grer RabbitMQ dans les routes api-clients

**PrioritÃ© :** ğŸ”´ Critique  
**Estimation :** 15 min  
**DÃ©pend de :** #001  
**Fichiers Ã  modifier :** `api-clients/app/routes.py`

### Modifications Ã  apporter

```python
# api-clients/app/routes.py
from . import rabbitmq  # Ajouter cet import

# Modifier POST /customers/
@router.post("/", response_model=schemas.ClientResponse, status_code=201)
def create_customer(client: schemas.ClientCreate, db: Session = Depends(get_db), api_key: str = Depends(verify_api_key)):
    db_client = crud.create_client(db=db, client=client)
    # Publier sur RabbitMQ
    rabbitmq.publish_client_created(db_client.id, {
        "nom": db_client.nom,
        "email": db_client.email,
        "adresse": db_client.adresse,
        "telephone": db_client.telephone
    })
    return db_client

# Modifier PUT /customers/{id}
@router.put("/{client_id}", response_model=schemas.ClientResponse)
def update_customer(client_id: int, client: schemas.ClientUpdate, db: Session = Depends(get_db), api_key: str = Depends(verify_api_key)):
    db_client = crud.update_client(db, client_id=client_id, client=client)
    if db_client is None:
        raise HTTPException(status_code=404, detail="Client non trouvÃ©")
    # Publier sur RabbitMQ
    rabbitmq.publish_client_updated(db_client.id, {
        "nom": db_client.nom,
        "email": db_client.email,
        "adresse": db_client.adresse,
        "telephone": db_client.telephone
    })
    return db_client

# Modifier DELETE /customers/{id}
@router.delete("/{client_id}", status_code=204)
def delete_customer(client_id: int, db: Session = Depends(get_db), api_key: str = Depends(verify_api_key)):
    success = crud.delete_client(db, client_id=client_id)
    if not success:
        raise HTTPException(status_code=404, detail="Client non trouvÃ©")
    # Publier sur RabbitMQ
    rabbitmq.publish_client_deleted(client_id)
```

### CritÃ¨res d'acceptation
- [ ] POST /customers publie `client.created`
- [ ] PUT /customers/{id} publie `client.updated`
- [ ] DELETE /customers/{id} publie `client.deleted`
- [ ] L'API fonctionne mÃªme si RabbitMQ est down

---

## ğŸ« TICKET #003 â€” CrÃ©er module RabbitMQ pour api-produits

**PrioritÃ© :** ğŸ”´ Critique  
**Estimation :** 30 min  
**Fichiers Ã  crÃ©er :** `api-produits/app/rabbitmq.py`

### Description
MÃªme logique que #001 mais pour les produits, avec une alerte stock bas.

### Ã‰vÃ©nements Ã  publier
| Routing Key | DÃ©clencheur |
|-------------|-------------|
| `produit.created` | Nouveau produit ajoutÃ© |
| `produit.updated` | Produit modifiÃ© |
| `produit.deleted` | Produit supprimÃ© |
| `produit.stock_low` | Stock < 10 unitÃ©s |

### Code spÃ©cifique
```python
def publish_produit_stock_low(produit_id: int, produit_nom: str, stock: int):
    """Alerte quand le stock est bas"""
    publish_message("produit.stock_low", {
        "event": "produit_stock_low",
        "produit_id": produit_id,
        "produit_nom": produit_nom,
        "stock_actuel": stock,
        "seuil_alerte": 10,
        "timestamp": __import__('datetime').datetime.utcnow().isoformat()
    })
```

### CritÃ¨res d'acceptation
- [ ] 4 fonctions de publication
- [ ] Alerte `stock_low` dÃ©clenchÃ©e si stock < 10 aprÃ¨s update
- [ ] DÃ©pendance `pika` dans requirements.txt

---

## ğŸ« TICKET #004 â€” IntÃ©grer RabbitMQ dans les routes api-produits

**PrioritÃ© :** ğŸ”´ Critique  
**Estimation :** 15 min  
**DÃ©pend de :** #003  
**Fichiers Ã  modifier :** `api-produits/app/routes.py`

### Logique spÃ©ciale
AprÃ¨s chaque PUT, vÃ©rifier si le stock < 10 :
```python
if db_produit.stock < 10:
    rabbitmq.publish_produit_stock_low(db_produit.id, db_produit.nom, db_produit.stock)
```

### CritÃ¨res d'acceptation
- [ ] Tous les endpoints CRUD publient sur RabbitMQ
- [ ] VÃ©rification du stock aprÃ¨s update â†’ alerte si < 10

---

## ğŸ« TICKET #005 â€” CrÃ©er module RabbitMQ pour api-commandes

**PrioritÃ© :** ğŸ”´ Critique  
**Estimation :** 30 min  
**Fichiers Ã  crÃ©er :** `api-commandes/app/rabbitmq.py`

### Ã‰vÃ©nements Ã  publier
| Routing Key | DÃ©clencheur |
|-------------|-------------|
| `commande.created` | Nouvelle commande |
| `commande.updated` | Statut modifiÃ© |
| `commande.deleted` | Commande supprimÃ©e |

### CritÃ¨res d'acceptation
- [ ] Publication sur les 3 Ã©vÃ©nements
- [ ] IntÃ©gration dans routes.py

---

## ğŸ« TICKET #006 â€” CrÃ©er consumer RabbitMQ pour api-commandes

**PrioritÃ© :** ğŸ”´ Critique  
**Estimation :** 45 min  
**DÃ©pend de :** #001, #003, #005  
**Fichiers Ã  crÃ©er :** `api-commandes/app/consumer.py`

### Description
L'api-commandes doit Ã©couter les Ã©vÃ©nements des autres services pour maintenir la cohÃ©rence.

### Code Ã  implÃ©menter

```python
# api-commandes/app/consumer.py
import pika
import json
import os
import logging
from .database import SessionLocal
from . import crud

logger = logging.getLogger(__name__)
RABBITMQ_URL = os.getenv("RABBITMQ_URL", "amqp://guest:guest@localhost:5672/")

def callback_client_deleted(ch, method, properties, body):
    """Quand un client est supprimÃ©, marquer ses commandes"""
    try:
        data = json.loads(body)
        client_id = data.get("client_id")
        logger.info(f"Client supprimÃ© dÃ©tectÃ©: {client_id}")
        
        db = SessionLocal()
        try:
            # Marquer les commandes du client comme "client_supprime"
            commandes = crud.get_commandes_by_client(db, client_id)
            for commande in commandes:
                crud.update_commande_statut(db, commande.id, "client_supprime")
            logger.info(f"{len(commandes)} commandes marquÃ©es")
        finally:
            db.close()
        
        ch.basic_ack(delivery_tag=method.delivery_tag)
    except Exception as e:
        logger.error(f"Erreur traitement client.deleted: {e}")
        ch.basic_nack(delivery_tag=method.delivery_tag, requeue=True)

def callback_produit_deleted(ch, method, properties, body):
    """Quand un produit est supprimÃ©"""
    try:
        data = json.loads(body)
        produit_id = data.get("produit_id")
        logger.info(f"Produit supprimÃ© dÃ©tectÃ©: {produit_id}")
        # Logique mÃ©tier si nÃ©cessaire
        ch.basic_ack(delivery_tag=method.delivery_tag)
    except Exception as e:
        logger.error(f"Erreur traitement produit.deleted: {e}")
        ch.basic_nack(delivery_tag=method.delivery_tag, requeue=True)

def start_consumer():
    """Lance le consumer RabbitMQ"""
    logger.info("DÃ©marrage du consumer RabbitMQ...")
    
    connection = pika.BlockingConnection(pika.URLParameters(RABBITMQ_URL))
    channel = connection.channel()
    
    # DÃ©clarer l'exchange
    channel.exchange_declare(exchange='payetonkawa', exchange_type='topic', durable=True)
    
    # Queue pour les Ã©vÃ©nements clients
    channel.queue_declare(queue='commandes_client_events', durable=True)
    channel.queue_bind(exchange='payetonkawa', queue='commandes_client_events', routing_key='client.deleted')
    
    # Queue pour les Ã©vÃ©nements produits
    channel.queue_declare(queue='commandes_produit_events', durable=True)
    channel.queue_bind(exchange='payetonkawa', queue='commandes_produit_events', routing_key='produit.deleted')
    
    # Consommer les messages
    channel.basic_qos(prefetch_count=1)
    channel.basic_consume(queue='commandes_client_events', on_message_callback=callback_client_deleted)
    channel.basic_consume(queue='commandes_produit_events', on_message_callback=callback_produit_deleted)
    
    logger.info("Consumer dÃ©marrÃ©, en attente de messages...")
    channel.start_consuming()

if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO)
    start_consumer()
```

### Ajout docker-compose.yml
```yaml
  consumer-commandes:
    build: ./api-commandes
    command: python -m app.consumer
    environment:
      DATABASE_URL: postgresql://faouz:faouz2020@db-commandes:5432/commandes_db
      RABBITMQ_URL: amqp://guest:guest@rabbitmq:5672/
    depends_on:
      - db-commandes
      - rabbitmq
    restart: unless-stopped
```

### CritÃ¨res d'acceptation
- [ ] Consumer Ã©coute `client.deleted` et `produit.deleted`
- [ ] Commandes marquÃ©es si client supprimÃ©
- [ ] Service ajoutÃ© dans docker-compose
- [ ] Logs des messages reÃ§us

---

# PHASE 2 â€” CI/CD (IntÃ©gration Continue)
> **Obligatoire** : automatisation des tests et dÃ©ploiements

---

## ğŸ« TICKET #007 â€” CrÃ©er workflow GitHub Actions pour tests

**PrioritÃ© :** ğŸ”´ Critique  
**Estimation :** 45 min  
**Fichiers Ã  crÃ©er :** `.github/workflows/ci.yml`

### Code Ã  implÃ©menter

```yaml
# .github/workflows/ci.yml
name: CI Pipeline PayeTonKawa

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main]

env:
  PYTHON_VERSION: '3.12'

jobs:
  # === Tests API Clients ===
  test-api-clients:
    runs-on: ubuntu-latest
    defaults:
      run:
        working-directory: api-clients
    
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_USER: test
          POSTGRES_PASSWORD: test
          POSTGRES_DB: test_clients
        ports:
          - 5432:5432
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
    
    steps:
      - uses: actions/checkout@v4
      
      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
          cache-dependency-path: api-clients/requirements.txt
      
      - name: Install dependencies
        run: pip install -r requirements.txt
      
      - name: Run tests with coverage
        env:
          DATABASE_URL: postgresql://test:test@localhost:5432/test_clients
          API_KEY: test-key
        run: pytest --cov=app --cov-report=xml --cov-report=term-missing -v
      
      - name: Upload coverage to Codecov
        uses: codecov/codecov-action@v4
        with:
          file: api-clients/coverage.xml
          flags: api-clients
          fail_ci_if_error: false

  # === Tests API Produits ===
  test-api-produits:
    runs-on: ubuntu-latest
    defaults:
      run:
        working-directory: api-produits
    
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_USER: test
          POSTGRES_PASSWORD: test
          POSTGRES_DB: test_produits
        ports:
          - 5433:5432
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
    
    steps:
      - uses: actions/checkout@v4
      
      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
          cache-dependency-path: api-produits/requirements.txt
      
      - name: Install dependencies
        run: pip install -r requirements.txt
      
      - name: Run tests with coverage
        env:
          DATABASE_URL: postgresql://test:test@localhost:5433/test_produits
          API_KEY: test-key
        run: pytest --cov=app --cov-report=xml --cov-report=term-missing -v
      
      - name: Upload coverage to Codecov
        uses: codecov/codecov-action@v4
        with:
          file: api-produits/coverage.xml
          flags: api-produits

  # === Tests API Commandes ===
  test-api-commandes:
    runs-on: ubuntu-latest
    defaults:
      run:
        working-directory: api-commandes
    
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_USER: test
          POSTGRES_PASSWORD: test
          POSTGRES_DB: test_commandes
        ports:
          - 5434:5432
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
    
    steps:
      - uses: actions/checkout@v4
      
      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
          cache-dependency-path: api-commandes/requirements.txt
      
      - name: Install dependencies
        run: pip install -r requirements.txt
      
      - name: Run tests with coverage
        env:
          DATABASE_URL: postgresql://test:test@localhost:5434/test_commandes
          API_KEY: test-key
        run: pytest --cov=app --cov-report=xml --cov-report=term-missing -v
      
      - name: Upload coverage to Codecov
        uses: codecov/codecov-action@v4
        with:
          file: api-commandes/coverage.xml
          flags: api-commandes

  # === Build Docker Images ===
  build-docker:
    needs: [test-api-clients, test-api-produits, test-api-commandes]
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'
    
    steps:
      - uses: actions/checkout@v4
      
      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3
      
      - name: Build API Clients
        uses: docker/build-push-action@v5
        with:
          context: ./api-clients
          push: false
          tags: payetonkawa/api-clients:${{ github.sha }}
          cache-from: type=gha
          cache-to: type=gha,mode=max
      
      - name: Build API Produits
        uses: docker/build-push-action@v5
        with:
          context: ./api-produits
          push: false
          tags: payetonkawa/api-produits:${{ github.sha }}
      
      - name: Build API Commandes
        uses: docker/build-push-action@v5
        with:
          context: ./api-commandes
          push: false
          tags: payetonkawa/api-commandes:${{ github.sha }}
      
      - name: Summary
        run: |
          echo "### âœ… Build successful!" >> $GITHUB_STEP_SUMMARY
          echo "Images built:" >> $GITHUB_STEP_SUMMARY
          echo "- payetonkawa/api-clients:${{ github.sha }}" >> $GITHUB_STEP_SUMMARY
          echo "- payetonkawa/api-produits:${{ github.sha }}" >> $GITHUB_STEP_SUMMARY
          echo "- payetonkawa/api-commandes:${{ github.sha }}" >> $GITHUB_STEP_SUMMARY
```

### CritÃ¨res d'acceptation
- [ ] Tests lancÃ©s sur push main/develop
- [ ] Tests lancÃ©s sur PR vers main
- [ ] 3 jobs parallÃ¨les (1 par API)
- [ ] Build Docker aprÃ¨s succÃ¨s des tests (main uniquement)
- [ ] Upload couverture vers Codecov

---

## ğŸ« TICKET #008 â€” Ajouter badges CI dans README

**PrioritÃ© :** ğŸŸ¢ Basse  
**Estimation :** 5 min  
**DÃ©pend de :** #007  
**Fichiers Ã  modifier :** `README.md`

### Ajout en haut du README
```markdown
# â˜• PayeTonKawa

![CI](https://github.com/Don-bot667/payetonkawa/actions/workflows/ci.yml/badge.svg)
[![codecov](https://codecov.io/gh/Don-bot667/payetonkawa/branch/main/graph/badge.svg)](https://codecov.io/gh/Don-bot667/payetonkawa)
```

---

## ğŸ« TICKET #009 â€” Documenter la stratÃ©gie GitFlow

**PrioritÃ© :** ğŸŸ¡ Important  
**Estimation :** 20 min  
**Fichiers Ã  crÃ©er :** `docs/GITFLOW.md`

### Contenu attendu
```markdown
# StratÃ©gie de Branches - GitFlow

## Branches principales
- `main` : Production, code stable
- `develop` : DÃ©veloppement, intÃ©gration

## Branches de travail
- `feature/xxx` : Nouvelles fonctionnalitÃ©s
- `bugfix/xxx` : Corrections de bugs
- `hotfix/xxx` : Corrections urgentes en production

## Workflow
1. CrÃ©er une branche depuis `develop`
2. DÃ©velopper et commiter
3. CrÃ©er une PR vers `develop`
4. Review + merge
5. Release : merge `develop` â†’ `main`

## Convention de commits
- `feat:` nouvelle fonctionnalitÃ©
- `fix:` correction de bug
- `docs:` documentation
- `test:` ajout de tests
- `refactor:` refactoring
```

---

# PHASE 3 â€” MONITORING
> **Obligatoire** : suivi des APIs et logs

---

## ğŸ« TICKET #010 â€” Ajouter endpoint /health

**PrioritÃ© :** ğŸŸ¡ Important  
**Estimation :** 20 min  
**Fichiers Ã  modifier :** `api-*/app/main.py`

### Code Ã  ajouter (dans chaque main.py)

```python
from sqlalchemy import text
from datetime import datetime

@app.get("/health", tags=["Health"])
def health_check():
    """Endpoint de healthcheck pour Docker/Kubernetes"""
    # VÃ©rifier connexion DB
    try:
        db = SessionLocal()
        db.execute(text("SELECT 1"))
        db.close()
        db_status = "connected"
    except Exception as e:
        db_status = f"error: {str(e)}"
    
    return {
        "status": "healthy" if db_status == "connected" else "unhealthy",
        "service": "api-clients",  # Adapter selon l'API
        "database": db_status,
        "timestamp": datetime.utcnow().isoformat(),
        "version": "1.0.0"
    }
```

### Ajout docker-compose.yml (pour chaque API)
```yaml
healthcheck:
  test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
  interval: 30s
  timeout: 10s
  retries: 3
  start_period: 40s
```

### CritÃ¨res d'acceptation
- [ ] Endpoint `/health` sur chaque API
- [ ] VÃ©rifie connexion DB
- [ ] Retourne status healthy/unhealthy
- [ ] Healthcheck configurÃ© dans docker-compose

---

## ğŸ« TICKET #011 â€” Ajouter logging structurÃ© (JSON)

**PrioritÃ© :** ğŸŸ¡ Important  
**Estimation :** 30 min  
**Fichiers Ã  crÃ©er :** `api-*/app/logging_config.py`

### Code Ã  implÃ©menter

```python
# api-clients/app/logging_config.py
import logging
import json
import sys
from datetime import datetime

class JSONFormatter(logging.Formatter):
    """Formateur de logs en JSON pour faciliter l'analyse"""
    
    def format(self, record):
        log_obj = {
            "timestamp": datetime.utcnow().isoformat() + "Z",
            "level": record.levelname,
            "logger": record.name,
            "message": record.getMessage(),
            "module": record.module,
            "function": record.funcName,
            "line": record.lineno
        }
        
        # Ajouter request_id si prÃ©sent
        if hasattr(record, 'request_id'):
            log_obj['request_id'] = record.request_id
        
        # Ajouter exception si prÃ©sente
        if record.exc_info:
            log_obj['exception'] = self.formatException(record.exc_info)
        
        return json.dumps(log_obj)

def setup_logging(service_name: str = "api"):
    """Configure le logging pour l'application"""
    logger = logging.getLogger(service_name)
    logger.setLevel(logging.INFO)
    
    # Handler console avec format JSON
    handler = logging.StreamHandler(sys.stdout)
    handler.setFormatter(JSONFormatter())
    logger.addHandler(handler)
    
    return logger

# Logger global
logger = setup_logging("payetonkawa")
```

### Utilisation dans routes.py
```python
from .logging_config import logger

@router.post("/", ...)
def create_customer(...):
    logger.info(f"CrÃ©ation client: {client.email}")
    db_client = crud.create_client(...)
    logger.info(f"Client crÃ©Ã© avec succÃ¨s", extra={"client_id": db_client.id})
    return db_client
```

### CritÃ¨res d'acceptation
- [ ] Logs en format JSON
- [ ] Timestamp ISO 8601
- [ ] Niveau, module, fonction, ligne inclus
- [ ] Logs sur CREATE, UPDATE, DELETE

---

## ğŸ« TICKET #012 â€” Ajouter middleware de logging des requÃªtes

**PrioritÃ© :** ğŸŸ¡ Important  
**Estimation :** 20 min  
**Fichiers Ã  modifier :** `api-*/app/main.py`

### Code Ã  ajouter

```python
import time
import uuid
from starlette.middleware.base import BaseHTTPMiddleware
from .logging_config import logger

class LoggingMiddleware(BaseHTTPMiddleware):
    async def dispatch(self, request, call_next):
        request_id = str(uuid.uuid4())[:8]
        start_time = time.time()
        
        # Log de la requÃªte entrante
        logger.info(f"Request started", extra={
            "request_id": request_id,
            "method": request.method,
            "path": request.url.path,
            "client_ip": request.client.host if request.client else "unknown"
        })
        
        response = await call_next(request)
        
        # Log de la rÃ©ponse
        duration_ms = (time.time() - start_time) * 1000
        logger.info(f"Request completed", extra={
            "request_id": request_id,
            "method": request.method,
            "path": request.url.path,
            "status_code": response.status_code,
            "duration_ms": round(duration_ms, 2)
        })
        
        # Ajouter request_id dans le header de rÃ©ponse
        response.headers["X-Request-ID"] = request_id
        return response

# Dans main.py
app.add_middleware(LoggingMiddleware)
```

### CritÃ¨res d'acceptation
- [ ] Chaque requÃªte loggÃ©e avec : method, path, status_code, duration_ms
- [ ] Request ID unique par requÃªte
- [ ] Header X-Request-ID dans la rÃ©ponse

---

# PHASE 4 â€” TESTS
> **Objectif** : atteindre 95% de couverture

---

## ğŸ« TICKET #013 â€” Augmenter couverture tests Ã  95%

**PrioritÃ© :** ğŸŸ¡ Important  
**Estimation :** 45 min  
**Fichiers Ã  modifier :** `api-*/tests/test_routes.py`

### Tests manquants Ã  ajouter

#### api-clients
```python
# Test email en double
def test_create_customer_duplicate_email(self, client, sample_client):
    """POST /customers - Email dÃ©jÃ  existant"""
    client.post("/customers/", json=sample_client, headers={"X-API-Key": "test-key"})
    response = client.post("/customers/", json=sample_client, headers={"X-API-Key": "test-key"})
    assert response.status_code == 400

# Test pagination
def test_get_customers_pagination(self, client, sample_client):
    """GET /customers - Pagination skip/limit"""
    # CrÃ©er 5 clients
    for i in range(5):
        data = sample_client.copy()
        data["email"] = f"test{i}@example.com"
        client.post("/customers/", json=data, headers={"X-API-Key": "test-key"})
    
    response = client.get("/customers/?skip=2&limit=2", headers={"X-API-Key": "test-key"})
    assert response.status_code == 200
    assert len(response.json()) == 2
```

#### api-produits
```python
# Test stock nÃ©gatif
def test_create_product_negative_stock(self, client):
    """POST /products - Stock nÃ©gatif refusÃ©"""
    response = client.post("/products/", json={
        "nom": "Test",
        "description": "Test",
        "prix": 10.0,
        "stock": -5
    }, headers={"X-API-Key": "test-key"})
    assert response.status_code == 422

# Test prix zÃ©ro
def test_create_product_zero_price(self, client):
    """POST /products - Prix zÃ©ro refusÃ©"""
    response = client.post("/products/", json={
        "nom": "Test",
        "description": "Test",
        "prix": 0,
        "stock": 10
    }, headers={"X-API-Key": "test-key"})
    assert response.status_code == 422
```

### CritÃ¨res d'acceptation
- [ ] Couverture â‰¥ 95% sur chaque API
- [ ] Tests des cas d'erreur (validation, duplicates)
- [ ] Tests de pagination

---

## ğŸ« TICKET #014 â€” Ajouter tests d'intÃ©gration RabbitMQ

**PrioritÃ© :** ğŸŸ¡ Important  
**Estimation :** 30 min  
**DÃ©pend de :** #001-#006  
**Fichiers Ã  crÃ©er :** `api-*/tests/test_rabbitmq.py`

### Code Ã  implÃ©menter

```python
# api-clients/tests/test_rabbitmq.py
import pytest
from unittest.mock import patch, MagicMock
from app import rabbitmq

class TestRabbitMQ:
    """Tests pour le module RabbitMQ"""
    
    @patch('app.rabbitmq.get_connection')
    def test_publish_message_success(self, mock_conn):
        """Test publication message rÃ©ussie"""
        mock_channel = MagicMock()
        mock_conn.return_value.channel.return_value = mock_channel
        
        result = rabbitmq.publish_message("test.event", {"data": "test"})
        
        assert result == True
        mock_channel.basic_publish.assert_called_once()
    
    @patch('app.rabbitmq.get_connection')
    def test_publish_message_connection_failed(self, mock_conn):
        """Test publication quand RabbitMQ down"""
        mock_conn.return_value = None
        
        result = rabbitmq.publish_message("test.event", {"data": "test"})
        
        assert result == False
    
    @patch('app.rabbitmq.publish_message')
    def test_publish_client_created(self, mock_publish):
        """Test publication Ã©vÃ©nement client crÃ©Ã©"""
        rabbitmq.publish_client_created(1, {"nom": "Test"})
        
        mock_publish.assert_called_once()
        args = mock_publish.call_args
        assert args[0][0] == "client.created"
        assert args[0][1]["client_id"] == 1
```

### CritÃ¨res d'acceptation
- [ ] Tests avec mock (pas besoin de RabbitMQ rÃ©el)
- [ ] Test succÃ¨s publication
- [ ] Test Ã©chec connexion
- [ ] Test pour chaque Ã©vÃ©nement

---

# PHASE 5 â€” DOCUMENTATION
> **Obligatoire** : documentation technique complÃ¨te

---

## ğŸ« TICKET #015 â€” CrÃ©er documentation architecture

**PrioritÃ© :** ğŸ”´ Critique  
**Estimation :** 1h  
**Fichiers Ã  crÃ©er :** `docs/ARCHITECTURE.md`

### Contenu attendu

```markdown
# Architecture PayeTonKawa

## Vue d'ensemble

PayeTonKawa utilise une architecture **micro-services** composÃ©e de 3 APIs indÃ©pendantes communicant via un message broker (RabbitMQ).

## SchÃ©ma d'architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         CLIENTS                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚  Site Web    â”‚    â”‚   Gestion    â”‚    â”‚  Revendeurs  â”‚       â”‚
â”‚  â”‚   (Astro)    â”‚    â”‚   (Astro)    â”‚    â”‚    (API)     â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                   â”‚                   â”‚
          â–¼                   â–¼                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     API GATEWAY (CORS + Auth)                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                   â”‚                   â”‚
          â–¼                   â–¼                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  API Clients    â”‚ â”‚  API Produits   â”‚ â”‚  API Commandes  â”‚
â”‚    :8000        â”‚ â”‚     :8001       â”‚ â”‚     :8002       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚ â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚ â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  FastAPI  â”‚  â”‚ â”‚  â”‚  FastAPI  â”‚  â”‚ â”‚  â”‚  FastAPI  â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â”‚ â”‚  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â”‚ â”‚  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â”‚
â”‚        â”‚        â”‚ â”‚        â”‚        â”‚ â”‚        â”‚        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”  â”‚ â”‚  â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”  â”‚ â”‚  â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚PostgreSQL â”‚  â”‚ â”‚  â”‚PostgreSQL â”‚  â”‚ â”‚  â”‚PostgreSQL â”‚  â”‚
â”‚  â”‚clients_db â”‚  â”‚ â”‚  â”‚produits_dbâ”‚  â”‚ â”‚  â”‚commandes_dbâ”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚ â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚ â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                   â”‚                   â”‚
         â”‚    publish        â”‚    publish        â”‚    consume
         â–¼                   â–¼                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        RABBITMQ                                  â”‚
â”‚  Exchange: payetonkawa (topic)                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚
â”‚  â”‚client.*     â”‚ â”‚produit.*    â”‚ â”‚commande.*   â”‚                â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Services

| Service | Port | Base de donnÃ©es | Description |
|---------|------|-----------------|-------------|
| api-clients | 8000 | clients_db | Gestion des clients (CRUD) |
| api-produits | 8001 | produits_db | Catalogue produits (CRUD + stock) |
| api-commandes | 8002 | commandes_db | Gestion des commandes |
| RabbitMQ | 5672/15672 | - | Message broker |

## Communication inter-services

### Ã‰vÃ©nements publiÃ©s

| Service | Ã‰vÃ©nement | Description |
|---------|-----------|-------------|
| api-clients | `client.created` | Nouveau client crÃ©Ã© |
| api-clients | `client.updated` | Client modifiÃ© |
| api-clients | `client.deleted` | Client supprimÃ© |
| api-produits | `produit.created` | Nouveau produit |
| api-produits | `produit.updated` | Produit modifiÃ© |
| api-produits | `produit.deleted` | Produit supprimÃ© |
| api-produits | `produit.stock_low` | Stock < 10 |
| api-commandes | `commande.created` | Nouvelle commande |
| api-commandes | `commande.updated` | Statut modifiÃ© |

### Abonnements

| Service | Ã‰coute | Action |
|---------|--------|--------|
| api-commandes | `client.deleted` | Marque les commandes du client |
| api-commandes | `produit.deleted` | Notifie les commandes concernÃ©es |

## Justifications techniques

### Langage : Python + FastAPI
- **Performance** : FastAPI est un des frameworks Python les plus rapides (basÃ© sur Starlette)
- **ProductivitÃ©** : Validation automatique, documentation OpenAPI auto-gÃ©nÃ©rÃ©e
- **Typage** : Support natif des type hints Python
- **Async** : Support natif de l'asynchrone

### Base de donnÃ©es : PostgreSQL
- **FiabilitÃ©** : ACID compliant, intÃ©gritÃ© rÃ©fÃ©rentielle
- **Performance** : Indexation avancÃ©e, requÃªtes optimisÃ©es
- **ScalabilitÃ©** : Support du partitioning, rÃ©plication
- **Ã‰cosystÃ¨me** : Large communautÃ©, outils matures

### Message Broker : RabbitMQ
- **FiabilitÃ©** : Persistance des messages, acknowledgments
- **FlexibilitÃ©** : Routing via exchanges (topic, direct, fanout)
- **Monitoring** : Interface web de management
- **Standards** : Support AMQP 0.9.1
```

### CritÃ¨res d'acceptation
- [ ] SchÃ©ma ASCII ou Mermaid de l'architecture
- [ ] Description de chaque service
- [ ] Justification du langage (Python/FastAPI)
- [ ] Justification de la BDD (PostgreSQL)
- [ ] Justification du message broker (RabbitMQ)

---

## ğŸ« TICKET #016 â€” CrÃ©er documentation sÃ©curitÃ©

**PrioritÃ© :** ğŸ”´ Critique  
**Estimation :** 30 min  
**Fichiers Ã  crÃ©er :** `docs/SECURITE.md`

### Contenu attendu

```markdown
# SÃ©curitÃ© PayeTonKawa

## Authentification

### API Key
Toutes les APIs sont protÃ©gÃ©es par une clÃ© API transmise dans le header `X-API-Key`.

```bash
curl -H "X-API-Key: votre-cle-api" https://api.payetonkawa.fr/customers/
```

### Endpoints publics
- `GET /` : Message de bienvenue
- `GET /health` : Healthcheck
- `GET /docs` : Documentation Swagger

## OWASP TOP 10 - Mesures appliquÃ©es

| Risque | Mesure |
|--------|--------|
| A01 - Broken Access Control | API Key obligatoire, validation des permissions |
| A02 - Cryptographic Failures | HTTPS en production, mots de passe hashÃ©s |
| A03 - Injection | ORM SQLAlchemy (requÃªtes paramÃ©trÃ©es), validation Pydantic |
| A04 - Insecure Design | Architecture micro-services, principe du moindre privilÃ¨ge |
| A05 - Security Misconfiguration | CORS restrictif, headers sÃ©curisÃ©s |
| A06 - Vulnerable Components | DÃ©pendances Ã  jour, scan de sÃ©curitÃ© CI |
| A07 - Auth Failures | Rate limiting, API Key rotation |
| A08 - Data Integrity Failures | Validation stricte des entrÃ©es |
| A09 - Security Logging | Logs structurÃ©s, alertes |
| A10 - SSRF | Pas d'appels externes non contrÃ´lÃ©s |

## Validation des entrÃ©es

Toutes les donnÃ©es sont validÃ©es via Pydantic :

```python
class ClientCreate(BaseModel):
    nom: str = Field(..., min_length=2, max_length=100)
    email: EmailStr
    telephone: str = Field(..., pattern=r'^0[1-9][0-9]{8}$')
```

## CORS

Configuration restrictive des origines autorisÃ©es :

```python
ALLOWED_ORIGINS = ["https://payetonkawa.fr", "https://gestion.payetonkawa.fr"]
```

## Gestion des secrets

| Secret | Stockage |
|--------|----------|
| API_KEY | Variable d'environnement |
| DATABASE_URL | Variable d'environnement |
| RABBITMQ_URL | Variable d'environnement |

**Ne jamais commiter de secrets dans le code !**

## Recommandations production

1. Utiliser HTTPS uniquement
2. Activer le rate limiting
3. Rotation rÃ©guliÃ¨re des API Keys
4. Monitoring des accÃ¨s suspects
5. Backup rÃ©gulier des bases de donnÃ©es
```

---

## ğŸ« TICKET #017 â€” CrÃ©er documentation hÃ©bergement/scaling

**PrioritÃ© :** ğŸ”´ Critique  
**Estimation :** 30 min  
**Fichiers Ã  crÃ©er :** `docs/HEBERGEMENT.md`

### Contenu attendu

```markdown
# HÃ©bergement & Scaling PayeTonKawa

## DÃ©ploiement local (dÃ©veloppement)

```bash
git clone https://github.com/Don-bot667/payetonkawa.git
cd payetonkawa
docker-compose up -d
```

## DÃ©ploiement production

### Option 1 : VPS (RecommandÃ© pour dÃ©marrer)
- **Provider** : OVH, Scaleway, DigitalOcean
- **Config minimale** : 4 vCPU, 8 Go RAM, 50 Go SSD
- **CoÃ»t** : ~30-50â‚¬/mois

### Option 2 : Kubernetes (ScalabilitÃ©)
- **Provider** : AWS EKS, Google GKE, Azure AKS
- **Avantages** : Auto-scaling, haute disponibilitÃ©
- **CoÃ»t** : Variable selon usage

### Option 3 : PaaS (SimplicitÃ©)
- **Provider** : Heroku, Railway, Render
- **Avantages** : DÃ©ploiement simplifiÃ©
- **CoÃ»t** : ~50-100â‚¬/mois

## Scaling horizontal

Chaque API peut Ãªtre rÃ©pliquÃ©e indÃ©pendamment :

```yaml
# docker-compose.prod.yml
services:
  api-produits:
    deploy:
      replicas: 3  # 3 instances
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
```

### Load Balancing
Utiliser un reverse proxy (Nginx, Traefik) pour distribuer le trafic :

```
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   Load Balancer â”‚
                    â”‚     (Nginx)     â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â–¼                 â–¼                 â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ API Produitsâ”‚   â”‚ API Produitsâ”‚   â”‚ API Produitsâ”‚
    â”‚  Instance 1 â”‚   â”‚  Instance 2 â”‚   â”‚  Instance 3 â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Base de donnÃ©es

### Scaling vertical
Augmenter les ressources du serveur PostgreSQL.

### Scaling horizontal
- Read replicas pour les requÃªtes de lecture
- Connection pooling (PgBouncer)

## Monitoring production

- **MÃ©triques** : Prometheus + Grafana
- **Logs** : ELK Stack ou Loki
- **Alertes** : AlertManager, PagerDuty
```

---

## ğŸ« TICKET #018 â€” ComplÃ©ter le README principal

**PrioritÃ© :** ğŸ”´ Critique  
**Estimation :** 45 min  
**Fichiers Ã  modifier :** `README.md`

### Structure complÃ¨te

```markdown
# â˜• PayeTonKawa

> Application e-commerce de vente de cafÃ© - Architecture Micro-services

![CI](https://github.com/Don-bot667/payetonkawa/actions/workflows/ci.yml/badge.svg)
[![codecov](https://codecov.io/gh/Don-bot667/payetonkawa/branch/main/graph/badge.svg)](https://codecov.io/gh/Don-bot667/payetonkawa)

## ğŸ“‹ Table des matiÃ¨res

- [PrÃ©sentation](#-prÃ©sentation)
- [Architecture](#-architecture)
- [Installation](#-installation)
- [Utilisation](#-utilisation)
- [API Documentation](#-api-documentation)
- [Tests](#-tests)
- [DÃ©ploiement](#-dÃ©ploiement)
- [Documentation](#-documentation)

## ğŸ¯ PrÃ©sentation

PayeTonKawa est une application e-commerce spÃ©cialisÃ©e dans la vente de cafÃ©, construite avec une architecture micro-services moderne.

### FonctionnalitÃ©s
- ğŸ§‘â€ğŸ’¼ Gestion des clients
- â˜• Catalogue de produits avec gestion des stocks
- ğŸ“¦ Gestion des commandes
- ğŸ”„ Synchronisation temps rÃ©el via RabbitMQ
- ğŸ” API sÃ©curisÃ©e par API Key

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ API Clients â”‚  â”‚API Produits â”‚  â”‚API Commandesâ”‚
â”‚    :8000    â”‚  â”‚    :8001    â”‚  â”‚    :8002    â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚                â”‚                â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                 â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
                 â”‚  RabbitMQ   â”‚
                 â”‚  :5672      â”‚
                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

| Service | Port | Description |
|---------|------|-------------|
| api-clients | 8000 | Gestion des clients |
| api-produits | 8001 | Catalogue produits |
| api-commandes | 8002 | Gestion commandes |
| RabbitMQ | 5672 / 15672 | Message broker |

## ğŸš€ Installation

### PrÃ©requis
- Docker & Docker Compose
- Git

### Lancement rapide

```bash
# Cloner le projet
git clone https://github.com/Don-bot667/payetonkawa.git
cd payetonkawa

# Lancer tous les services
docker-compose up -d

# VÃ©rifier le statut
docker-compose ps
```

### URLs locales
| Service | URL |
|---------|-----|
| API Clients | http://localhost:8000/docs |
| API Produits | http://localhost:8001/docs |
| API Commandes | http://localhost:8002/docs |
| RabbitMQ Management | http://localhost:15672 |

## ğŸ“– API Documentation

Chaque API expose une documentation Swagger interactive sur `/docs`.

### Authentification

Ajouter le header `X-API-Key` Ã  chaque requÃªte :

```bash
curl -H "X-API-Key: secret_key_123" http://localhost:8000/customers/
```

### Exemples

```bash
# CrÃ©er un client
curl -X POST http://localhost:8000/customers/ \
  -H "X-API-Key: secret_key_123" \
  -H "Content-Type: application/json" \
  -d '{"nom": "Jean Dupont", "email": "jean@example.com", "adresse": "Paris", "telephone": "0612345678"}'

# Lister les produits
curl -H "X-API-Key: secret_key_123" http://localhost:8001/products/
```

## ğŸ§ª Tests

```bash
# Installer les dÃ©pendances de test
pip install pytest pytest-cov

# Lancer tous les tests
pytest

# Avec couverture
pytest --cov=api-clients/app --cov=api-produits/app --cov=api-commandes/app

# Tests d'une seule API
cd api-clients && pytest
```

## ğŸ“š Documentation

- [Architecture](docs/ARCHITECTURE.md)
- [SÃ©curitÃ©](docs/SECURITE.md)
- [HÃ©bergement & Scaling](docs/HEBERGEMENT.md)
- [GitFlow](docs/GITFLOW.md)
- [Conduite du changement](docs/CONDUITE_CHANGEMENT.md)

## ğŸ‘¨â€ğŸ’» Auteur

**Don** - 2026

---

*Projet rÃ©alisÃ© dans le cadre du MSPR TPRE814 - EISI*
```

---

## ğŸ« TICKET #019 â€” CrÃ©er documentation API (endpoints)

**PrioritÃ© :** ğŸŸ¡ Important  
**Estimation :** 30 min  
**Fichiers Ã  crÃ©er :** `docs/API.md`

### Contenu : documenter tous les endpoints de chaque API avec exemples

---

# PHASE 6 â€” POSTMAN
> **Obligatoire** : collection de tests manuels

---

## ğŸ« TICKET #020 â€” CrÃ©er collection Postman complÃ¨te

**PrioritÃ© :** ğŸ”´ Critique  
**Estimation :** 45 min  
**Fichiers Ã  crÃ©er :**
- `postman/PayeTonKawa.postman_collection.json`
- `postman/PayeTonKawa_local.postman_environment.json`

### Structure de la collection

```
ğŸ“ PayeTonKawa
â”œâ”€â”€ ğŸ“ Clients
â”‚   â”œâ”€â”€ GET Liste des clients
â”‚   â”œâ”€â”€ GET Client par ID
â”‚   â”œâ”€â”€ POST CrÃ©er un client
â”‚   â”œâ”€â”€ PUT Modifier un client
â”‚   â””â”€â”€ DELETE Supprimer un client
â”œâ”€â”€ ğŸ“ Produits
â”‚   â”œâ”€â”€ GET Liste des produits
â”‚   â”œâ”€â”€ GET Produit par ID
â”‚   â”œâ”€â”€ POST CrÃ©er un produit
â”‚   â”œâ”€â”€ PUT Modifier un produit
â”‚   â””â”€â”€ DELETE Supprimer un produit
â”œâ”€â”€ ğŸ“ Commandes
â”‚   â”œâ”€â”€ GET Liste des commandes
â”‚   â”œâ”€â”€ GET Commande par ID
â”‚   â”œâ”€â”€ GET Commandes d'un client
â”‚   â”œâ”€â”€ POST CrÃ©er une commande
â”‚   â”œâ”€â”€ PUT Modifier statut
â”‚   â””â”€â”€ DELETE Supprimer une commande
â””â”€â”€ ğŸ“ Health
    â”œâ”€â”€ GET Health API Clients
    â”œâ”€â”€ GET Health API Produits
    â””â”€â”€ GET Health API Commandes
```

### Variables d'environnement

```json
{
  "id": "payetonkawa-local",
  "name": "PayeTonKawa - Local",
  "values": [
    {"key": "base_url_clients", "value": "http://localhost:8000"},
    {"key": "base_url_produits", "value": "http://localhost:8001"},
    {"key": "base_url_commandes", "value": "http://localhost:8002"},
    {"key": "api_key", "value": "secret_key_123"}
  ]
}
```

### CritÃ¨res d'acceptation
- [ ] Toutes les routes documentÃ©es
- [ ] Variables d'environnement utilisÃ©es
- [ ] Exemples de body pour POST/PUT
- [ ] Tests automatiques dans Postman (status code)

---

# PHASE 7 â€” CONDUITE DU CHANGEMENT
> **Obligatoire** : accompagnement de la transition

---

## ğŸ« TICKET #021 â€” RÃ©diger plan de conduite du changement

**PrioritÃ© :** ğŸ”´ Critique  
**Estimation :** 1h30  
**Fichiers Ã  crÃ©er :** `docs/CONDUITE_CHANGEMENT.md`

### Contenu attendu

```markdown
# Plan de Conduite du Changement

## Contexte

PayeTonKawa passe d'une architecture monolithique Ã  une architecture micro-services, et d'un cycle en V Ã  une mÃ©thodologie Agile.

## Changements identifiÃ©s

### 1. Changements techniques
| Avant | AprÃ¨s |
|-------|-------|
| Application monolithique | 3 micro-services indÃ©pendants |
| Base de donnÃ©es unique | 1 BDD par service |
| DÃ©ploiement manuel | CI/CD automatisÃ© |
| Communication synchrone | Communication asynchrone (RabbitMQ) |

### 2. Changements organisationnels
| Avant | AprÃ¨s |
|-------|-------|
| Cycle en V | MÃ©thodologie Agile (Scrum) |
| 1 Ã©quipe de 3 personnes | 3 Ã©quipes dÃ©diÃ©es (1 par service) |
| Sollicitation directe des devs | Backlog gÃ©rÃ© par Product Owner |
| DÃ©ploiements rares | DÃ©ploiements frÃ©quents |

## Plan d'action - Les 4 axes

### 1. INFORMER ğŸ“¢
| Action | Cible | Timing |
|--------|-------|--------|
| PrÃ©sentation de la nouvelle architecture | Toute l'Ã©quipe | J-30 |
| Documentation technique | DÃ©veloppeurs | J-20 |
| FAQ changements | Tous | Continu |

### 2. COMMUNIQUER ğŸ’¬
| Action | Cible | FrÃ©quence |
|--------|-------|-----------|
| RÃ©union de lancement | Direction + Ã‰quipes | 1 fois |
| Stand-up daily | Ã‰quipes dev | Quotidien |
| Sprint review | Tous stakeholders | Bi-hebdo |
| Newsletter projet | Toute l'entreprise | Mensuel |

### 3. FORMER ğŸ“š
| Formation | DurÃ©e | Cible |
|-----------|-------|-------|
| Architecture micro-services | 1 jour | DÃ©veloppeurs |
| Docker & conteneurisation | 1 jour | DÃ©veloppeurs + Ops |
| RabbitMQ | 0.5 jour | DÃ©veloppeurs |
| MÃ©thodologie Agile/Scrum | 1 jour | Toute l'Ã©quipe |
| CI/CD avec GitHub Actions | 0.5 jour | DÃ©veloppeurs |

### 4. FAIRE PARTICIPER ğŸ¤
| Action | Participants |
|--------|--------------|
| Choix des technologies | DÃ©veloppeurs seniors |
| DÃ©finition des standards de code | Ã‰quipe dev |
| Tests utilisateurs | Ã‰quipe commerciale |
| Retours sprint review | Tous |

## ModÃ¨le de transition de Bridges

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                             â”‚
â”‚  PHASE 1          PHASE 2              PHASE 3              â”‚
â”‚  Fin              Zone neutre          Nouveau dÃ©part       â”‚
â”‚                                                             â”‚
â”‚  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ         â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ         â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     â”‚
â”‚                                                             â”‚
â”‚  Accepter         Adaptation           Engagement           â”‚
â”‚  le changement    Apprentissage        Innovation           â”‚
â”‚                                                             â”‚
â”‚  Semaine 1-2      Semaine 3-6          Semaine 7+           â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## RÃ©sistances anticipÃ©es et solutions

| RÃ©sistance | Solution |
|------------|----------|
| "Ã‡a marchait bien avant" | Montrer les limites de l'ancien systÃ¨me |
| "C'est trop compliquÃ©" | Formation + accompagnement |
| "On n'a pas le temps" | DÃ©montrer les gains de productivitÃ© |
| "Qui va gÃ©rer tout Ã§a ?" | DÃ©finir clairement les rÃ´les |

## Planning de transition

```
Mois 1: PrÃ©paration
â”œâ”€â”€ Semaine 1-2: Formation architecture
â”œâ”€â”€ Semaine 3-4: Formation Agile

Mois 2: Mise en place
â”œâ”€â”€ Semaine 1-2: DÃ©ploiement environnement
â”œâ”€â”€ Semaine 3-4: Premier sprint

Mois 3: Optimisation
â”œâ”€â”€ RÃ©trospectives
â”œâ”€â”€ Ajustements process
â””â”€â”€ Autonomie des Ã©quipes
```

## KPIs de succÃ¨s

| Indicateur | Objectif |
|------------|----------|
| Satisfaction Ã©quipe | > 7/10 |
| Temps de dÃ©ploiement | < 30 min |
| FrÃ©quence de dÃ©ploiement | > 1/semaine |
| Couverture de tests | > 90% |
| Bugs en production | < 2/mois |

## Outils recommandÃ©s

- **Gestion de projet** : Jira, Trello
- **Communication** : Slack, Teams
- **Documentation** : Confluence, Notion
- **CI/CD** : GitHub Actions
- **Monitoring** : Grafana
```

### CritÃ¨res d'acceptation
- [ ] 4 axes couverts (Informer, Communiquer, Former, Participer)

